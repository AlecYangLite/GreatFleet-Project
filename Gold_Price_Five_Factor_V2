{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNvEeGRlCQPHZGcC5gPTSA8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlecYangLite/GreatFleet-Project/blob/main/Gold_Price_Five_Factor_V2\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1️⃣ 导入依赖\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Bidirectional, Multiply\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n"
      ],
      "metadata": {
        "id": "3pSfb7MWUD2-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2️⃣ 读取五因子数据\n",
        "factors = pd.read_csv('five_factors_data.csv', index_col=0, parse_dates=True)\n",
        "\n",
        "# 3️⃣ 多列归一化\n",
        "scaler = MinMaxScaler()\n",
        "factors_scaled = scaler.fit_transform(factors)\n",
        "factors_scaled = pd.DataFrame(factors_scaled, index=factors.index, columns=factors.columns)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x1mcUU_CNxGY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4️⃣ 创建序列 (time_step=90, 预测T+5)\n",
        "def create_multi_feature_sequences(data, time_step=90, forecast_horizon=5):\n",
        "    X, y = [], []\n",
        "    data_np = data.values\n",
        "    for i in range(len(data_np) - time_step - forecast_horizon):\n",
        "        X.append(data_np[i:i + time_step, :])\n",
        "        y.append(data_np[i + time_step:i + time_step + forecast_horizon, 0])  # 预测 GC=F\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X, y = create_multi_feature_sequences(factors_scaled, time_step=90, forecast_horizon=5)\n",
        "\n",
        "# 5️⃣ 滑动窗口分割\n",
        "def sliding_window_three_split(X, y, window_size=1000, slide_step=200, train_ratio=0.7, val_ratio=0.15):\n",
        "    windows = []\n",
        "    for start_idx in range(0, len(X) - window_size, slide_step):\n",
        "        end_idx = start_idx + window_size\n",
        "        X_window, y_window = X[start_idx:end_idx], y[start_idx:end_idx]\n",
        "\n",
        "        train_size = int(window_size * train_ratio)\n",
        "        val_size = int(window_size * val_ratio)\n",
        "\n",
        "        X_train, y_train = X_window[:train_size], y_window[:train_size]\n",
        "        X_val, y_val = X_window[train_size:train_size + val_size], y_window[train_size:train_size + val_size]\n",
        "        X_test, y_test = X_window[train_size + val_size:], y_window[train_size + val_size:]\n",
        "\n",
        "        windows.append({\n",
        "            'X_train': X_train, 'y_train': y_train,\n",
        "            'X_val': X_val, 'y_val': y_val,\n",
        "            'X_test': X_test, 'y_test': y_test\n",
        "        })\n",
        "    return windows\n",
        "\n",
        "windows = sliding_window_three_split(X, y, window_size=1000, slide_step=200)\n"
      ],
      "metadata": {
        "id": "2Pt5yLvMN0DV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 6️⃣ Attention 层\n",
        "def attention_3d_block(inputs):\n",
        "    input_dim = int(inputs.shape[2])\n",
        "    a = Dense(input_dim, activation='softmax')(inputs)\n",
        "    outputs = Multiply()([inputs, a])\n",
        "    return outputs\n",
        "\n",
        "# 7️⃣ 优化模型构建\n",
        "def build_optimized_multi_factor_model(input_shape, forecast_horizon=5):\n",
        "    input_layer = Input(shape=input_shape)\n",
        "    x = Bidirectional(LSTM(128, return_sequences=True))(input_layer)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = attention_3d_block(x)\n",
        "    x = LSTM(64, return_sequences=False)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "    output = Dense(forecast_horizon)(x)\n",
        "    model = Model(inputs=input_layer, outputs=output)\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=tf.keras.losses.Huber())\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "HNMgcw_pN3mn"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 8️⃣ 训练与评估\n",
        "all_rmse_per_step = []\n",
        "all_mae_per_step = []\n",
        "\n",
        "for idx, window in enumerate(windows):\n",
        "    X_train, y_train = window['X_train'], window['y_train']\n",
        "    X_val, y_val = window['X_val'], window['y_val']\n",
        "    X_test, y_test = window['X_test'], window['y_test']\n",
        "\n",
        "    model = build_optimized_multi_factor_model(input_shape=(X_train.shape[1], X_train.shape[2]), forecast_horizon=5)\n",
        "\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, verbose=1, min_lr=1e-6)\n",
        "\n",
        "    model.fit(X_train, y_train, epochs=60, batch_size=32,\n",
        "              validation_data=(X_val, y_val), verbose=1,\n",
        "              callbacks=[early_stop, reduce_lr])\n",
        "\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    # 计算误差\n",
        "    rmse_steps = []\n",
        "    mae_steps = []\n",
        "    for step in range(5):\n",
        "        rmse_step = np.sqrt(mean_squared_error(y_test[:, step], predictions[:, step]))\n",
        "        mae_step = mean_absolute_error(y_test[:, step], predictions[:, step])\n",
        "        rmse_steps.append(rmse_step)\n",
        "        mae_steps.append(mae_step)\n",
        "\n",
        "    all_rmse_per_step.append(rmse_steps)\n",
        "    all_mae_per_step.append(mae_steps)\n",
        "\n",
        "    print(f\"✅ 第 {idx+1} 个滑动窗口训练完成\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8rFjKD6N7OT",
        "outputId": "5c0fbb5f-dc55-4a49-a839-44166a7d2de0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - loss: 0.0949 - val_loss: 0.0500 - learning_rate: 0.0010\n",
            "Epoch 2/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0521 - val_loss: 0.0435 - learning_rate: 0.0010\n",
            "Epoch 3/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0379 - val_loss: 0.0358 - learning_rate: 0.0010\n",
            "Epoch 4/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0273 - val_loss: 0.0306 - learning_rate: 0.0010\n",
            "Epoch 5/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0204 - val_loss: 0.0192 - learning_rate: 0.0010\n",
            "Epoch 6/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0160 - val_loss: 0.0158 - learning_rate: 0.0010\n",
            "Epoch 7/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0129 - val_loss: 0.0171 - learning_rate: 0.0010\n",
            "Epoch 8/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0093 - val_loss: 0.0166 - learning_rate: 0.0010\n",
            "Epoch 9/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0069 - val_loss: 0.0165 - learning_rate: 0.0010\n",
            "Epoch 10/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0055 - val_loss: 0.0140 - learning_rate: 0.0010\n",
            "Epoch 11/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0040 - val_loss: 0.0147 - learning_rate: 0.0010\n",
            "Epoch 12/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0031 - val_loss: 0.0118 - learning_rate: 0.0010\n",
            "Epoch 13/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0025 - val_loss: 0.0142 - learning_rate: 0.0010\n",
            "Epoch 14/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0020 - val_loss: 0.0132 - learning_rate: 0.0010\n",
            "Epoch 15/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0017 - val_loss: 0.0115 - learning_rate: 0.0010\n",
            "Epoch 16/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0014 - val_loss: 0.0109 - learning_rate: 0.0010\n",
            "Epoch 17/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0012 - val_loss: 0.0101 - learning_rate: 0.0010\n",
            "Epoch 18/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0112 - learning_rate: 0.0010\n",
            "Epoch 19/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0010 - val_loss: 0.0080 - learning_rate: 0.0010\n",
            "Epoch 20/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.3965e-04 - val_loss: 0.0128 - learning_rate: 0.0010\n",
            "Epoch 21/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.1411e-04 - val_loss: 0.0174 - learning_rate: 0.0010\n",
            "Epoch 22/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 8.1520e-04 - val_loss: 0.0090 - learning_rate: 0.0010\n",
            "Epoch 23/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 5.9809e-04 - val_loss: 0.0078 - learning_rate: 0.0010\n",
            "Epoch 24/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.1491e-04 - val_loss: 0.0102 - learning_rate: 0.0010\n",
            "Epoch 25/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 6.2361e-04 - val_loss: 0.0096 - learning_rate: 0.0010\n",
            "Epoch 26/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.7013e-04 - val_loss: 0.0074 - learning_rate: 0.0010\n",
            "Epoch 27/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 5.4232e-04 - val_loss: 0.0101 - learning_rate: 0.0010\n",
            "Epoch 28/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 4.8137e-04 - val_loss: 0.0077 - learning_rate: 0.0010\n",
            "Epoch 29/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 4.2626e-04 - val_loss: 0.0098 - learning_rate: 0.0010\n",
            "Epoch 30/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.3112e-04\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 4.3197e-04 - val_loss: 0.0092 - learning_rate: 0.0010\n",
            "Epoch 31/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.2455e-04 - val_loss: 0.0080 - learning_rate: 5.0000e-04\n",
            "Epoch 32/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.1641e-04 - val_loss: 0.0084 - learning_rate: 5.0000e-04\n",
            "Epoch 33/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.4469e-04 - val_loss: 0.0077 - learning_rate: 5.0000e-04\n",
            "Epoch 34/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.5809e-04\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.5673e-04 - val_loss: 0.0082 - learning_rate: 5.0000e-04\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "✅ 第 1 个滑动窗口训练完成\n",
            "Epoch 1/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0926 - val_loss: 0.0525 - learning_rate: 0.0010\n",
            "Epoch 2/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0507 - val_loss: 0.0445 - learning_rate: 0.0010\n",
            "Epoch 3/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0387 - val_loss: 0.0370 - learning_rate: 0.0010\n",
            "Epoch 4/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0280 - val_loss: 0.0211 - learning_rate: 0.0010\n",
            "Epoch 5/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0199 - val_loss: 0.0148 - learning_rate: 0.0010\n",
            "Epoch 6/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0148 - val_loss: 0.0111 - learning_rate: 0.0010\n",
            "Epoch 7/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0104 - val_loss: 0.0078 - learning_rate: 0.0010\n",
            "Epoch 8/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0076 - val_loss: 0.0056 - learning_rate: 0.0010\n",
            "Epoch 9/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0055 - val_loss: 0.0041 - learning_rate: 0.0010\n",
            "Epoch 10/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0042 - val_loss: 0.0029 - learning_rate: 0.0010\n",
            "Epoch 11/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0031 - val_loss: 0.0021 - learning_rate: 0.0010\n",
            "Epoch 12/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0023 - val_loss: 0.0021 - learning_rate: 0.0010\n",
            "Epoch 13/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0017 - val_loss: 0.0013 - learning_rate: 0.0010\n",
            "Epoch 14/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0013 - val_loss: 8.7328e-04 - learning_rate: 0.0010\n",
            "Epoch 15/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0010 - val_loss: 6.5835e-04 - learning_rate: 0.0010\n",
            "Epoch 16/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 8.8000e-04 - val_loss: 9.1508e-04 - learning_rate: 0.0010\n",
            "Epoch 17/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.9686e-04 - val_loss: 4.6783e-04 - learning_rate: 0.0010\n",
            "Epoch 18/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.6849e-04 - val_loss: 5.1183e-04 - learning_rate: 0.0010\n",
            "Epoch 19/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.0572e-04 - val_loss: 3.6343e-04 - learning_rate: 0.0010\n",
            "Epoch 20/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 5.2331e-04 - val_loss: 3.7014e-04 - learning_rate: 0.0010\n",
            "Epoch 21/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.7992e-04 - val_loss: 2.8338e-04 - learning_rate: 0.0010\n",
            "Epoch 22/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 4.9648e-04 - val_loss: 3.6052e-04 - learning_rate: 0.0010\n",
            "Epoch 23/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.1224e-04\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.1200e-04 - val_loss: 5.2470e-04 - learning_rate: 0.0010\n",
            "Epoch 24/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 4.9802e-04 - val_loss: 3.1932e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 25/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.0428e-04 - val_loss: 2.6157e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 26/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.5527e-04 - val_loss: 2.5397e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 27/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.7614e-04 - val_loss: 2.6762e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 28/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 3.7768e-04 - val_loss: 2.5562e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 29/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.3976e-04\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 3.4200e-04 - val_loss: 2.5392e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 30/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 3.9602e-04 - val_loss: 2.4209e-04 - learning_rate: 2.5000e-04\n",
            "Epoch 31/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 3.5328e-04 - val_loss: 2.4030e-04 - learning_rate: 2.5000e-04\n",
            "Epoch 32/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.4863e-04 - val_loss: 2.3463e-04 - learning_rate: 2.5000e-04\n",
            "Epoch 33/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.9443e-04\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.9597e-04 - val_loss: 2.1921e-04 - learning_rate: 2.5000e-04\n",
            "Epoch 34/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.3305e-04 - val_loss: 2.3063e-04 - learning_rate: 1.2500e-04\n",
            "Epoch 35/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.2205e-04 - val_loss: 2.2802e-04 - learning_rate: 1.2500e-04\n",
            "Epoch 36/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.2250e-04 - val_loss: 2.4030e-04 - learning_rate: 1.2500e-04\n",
            "Epoch 37/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.2787e-04\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.2587e-04 - val_loss: 2.2830e-04 - learning_rate: 1.2500e-04\n",
            "Epoch 38/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.3915e-04 - val_loss: 2.2617e-04 - learning_rate: 6.2500e-05\n",
            "Epoch 39/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.0936e-04 - val_loss: 2.2556e-04 - learning_rate: 6.2500e-05\n",
            "Epoch 40/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.8367e-04 - val_loss: 2.2762e-04 - learning_rate: 6.2500e-05\n",
            "Epoch 41/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.8807e-04\n",
            "Epoch 41: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 2.8905e-04 - val_loss: 2.2631e-04 - learning_rate: 6.2500e-05\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step\n",
            "✅ 第 2 个滑动窗口训练完成\n",
            "Epoch 1/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - loss: 0.0839 - val_loss: 0.0550 - learning_rate: 0.0010\n",
            "Epoch 2/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0506 - val_loss: 0.0425 - learning_rate: 0.0010\n",
            "Epoch 3/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0360 - val_loss: 0.0273 - learning_rate: 0.0010\n",
            "Epoch 4/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0251 - val_loss: 0.0198 - learning_rate: 0.0010\n",
            "Epoch 5/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0180 - val_loss: 0.0145 - learning_rate: 0.0010\n",
            "Epoch 6/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0130 - val_loss: 0.0103 - learning_rate: 0.0010\n",
            "Epoch 7/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0093 - val_loss: 0.0075 - learning_rate: 0.0010\n",
            "Epoch 8/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0067 - val_loss: 0.0055 - learning_rate: 0.0010\n",
            "Epoch 9/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0048 - val_loss: 0.0040 - learning_rate: 0.0010\n",
            "Epoch 10/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0035 - val_loss: 0.0027 - learning_rate: 0.0010\n",
            "Epoch 11/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0025 - val_loss: 0.0023 - learning_rate: 0.0010\n",
            "Epoch 12/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0018 - val_loss: 0.0016 - learning_rate: 0.0010\n",
            "Epoch 13/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0013 - val_loss: 0.0012 - learning_rate: 0.0010\n",
            "Epoch 14/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0010 - val_loss: 0.0012 - learning_rate: 0.0010\n",
            "Epoch 15/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.0603e-04 - val_loss: 0.0010 - learning_rate: 0.0010\n",
            "Epoch 16/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 7.7711e-04 - val_loss: 0.0011 - learning_rate: 0.0010\n",
            "Epoch 17/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.3504e-04 - val_loss: 0.0010 - learning_rate: 0.0010\n",
            "Epoch 18/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.5986e-04 - val_loss: 8.7634e-04 - learning_rate: 0.0010\n",
            "Epoch 19/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 5.1922e-04 - val_loss: 9.5291e-04 - learning_rate: 0.0010\n",
            "Epoch 20/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.8702e-04 - val_loss: 8.7727e-04 - learning_rate: 0.0010\n",
            "Epoch 21/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 4.6434e-04 - val_loss: 7.3407e-04 - learning_rate: 0.0010\n",
            "Epoch 22/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 3.6910e-04 - val_loss: 7.4136e-04 - learning_rate: 0.0010\n",
            "Epoch 23/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 3.9399e-04 - val_loss: 4.1497e-04 - learning_rate: 0.0010\n",
            "Epoch 24/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 4.7819e-04 - val_loss: 8.5688e-04 - learning_rate: 0.0010\n",
            "Epoch 25/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.5275e-04 - val_loss: 8.1934e-04 - learning_rate: 0.0010\n",
            "Epoch 26/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.5355e-04 - val_loss: 7.5219e-04 - learning_rate: 0.0010\n",
            "Epoch 27/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.7237e-04\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.7096e-04 - val_loss: 5.1885e-04 - learning_rate: 0.0010\n",
            "Epoch 28/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.7273e-04 - val_loss: 5.9898e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 29/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.8314e-04 - val_loss: 6.4644e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 30/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.8747e-04 - val_loss: 6.7103e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 31/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.3698e-04\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.3836e-04 - val_loss: 6.6384e-04 - learning_rate: 5.0000e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x798f4c65a160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 245ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x798f4c65a160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step\n",
            "✅ 第 3 个滑动窗口训练完成\n",
            "Epoch 1/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0737 - val_loss: 0.0529 - learning_rate: 0.0010\n",
            "Epoch 2/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0497 - val_loss: 0.0428 - learning_rate: 0.0010\n",
            "Epoch 3/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0354 - val_loss: 0.0275 - learning_rate: 0.0010\n",
            "Epoch 4/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0246 - val_loss: 0.0201 - learning_rate: 0.0010\n",
            "Epoch 5/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0198 - val_loss: 0.0154 - learning_rate: 0.0010\n",
            "Epoch 6/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0122 - val_loss: 0.0113 - learning_rate: 0.0010\n",
            "Epoch 7/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0086 - val_loss: 0.0083 - learning_rate: 0.0010\n",
            "Epoch 8/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0060 - val_loss: 0.0052 - learning_rate: 0.0010\n",
            "Epoch 9/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0042 - val_loss: 0.0038 - learning_rate: 0.0010\n",
            "Epoch 10/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0029 - val_loss: 0.0025 - learning_rate: 0.0010\n",
            "Epoch 11/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0021 - val_loss: 0.0020 - learning_rate: 0.0010\n",
            "Epoch 12/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0014 - val_loss: 0.0017 - learning_rate: 0.0010\n",
            "Epoch 13/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0011 - val_loss: 0.0018 - learning_rate: 0.0010\n",
            "Epoch 14/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.2716e-04 - val_loss: 0.0011 - learning_rate: 0.0010\n",
            "Epoch 15/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 5.9838e-04 - val_loss: 0.0011 - learning_rate: 0.0010\n",
            "Epoch 16/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 4.9288e-04 - val_loss: 0.0013 - learning_rate: 0.0010\n",
            "Epoch 17/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.4422e-04 - val_loss: 0.0016 - learning_rate: 0.0010\n",
            "Epoch 18/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.5161e-04\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.5131e-04 - val_loss: 0.0012 - learning_rate: 0.0010\n",
            "Epoch 19/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.9944e-04 - val_loss: 0.0010 - learning_rate: 5.0000e-04\n",
            "Epoch 20/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.5286e-04 - val_loss: 0.0012 - learning_rate: 5.0000e-04\n",
            "Epoch 21/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 2.9687e-04 - val_loss: 0.0012 - learning_rate: 5.0000e-04\n",
            "Epoch 22/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.6027e-04\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.6229e-04 - val_loss: 0.0012 - learning_rate: 5.0000e-04\n",
            "Epoch 23/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.7449e-04 - val_loss: 0.0011 - learning_rate: 2.5000e-04\n",
            "Epoch 24/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 2.7598e-04 - val_loss: 0.0010 - learning_rate: 2.5000e-04\n",
            "Epoch 25/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.0141e-04 - val_loss: 0.0012 - learning_rate: 2.5000e-04\n",
            "Epoch 26/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.5824e-04\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 2.5928e-04 - val_loss: 0.0011 - learning_rate: 2.5000e-04\n",
            "Epoch 27/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 2.6030e-04 - val_loss: 0.0010 - learning_rate: 1.2500e-04\n",
            "Epoch 28/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 2.3374e-04 - val_loss: 0.0011 - learning_rate: 1.2500e-04\n",
            "Epoch 29/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 2.5195e-04 - val_loss: 0.0011 - learning_rate: 1.2500e-04\n",
            "Epoch 30/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.4603e-04\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 2.4617e-04 - val_loss: 0.0012 - learning_rate: 1.2500e-04\n",
            "Epoch 31/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 2.6543e-04 - val_loss: 0.0011 - learning_rate: 6.2500e-05\n",
            "Epoch 32/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.5867e-04 - val_loss: 0.0011 - learning_rate: 6.2500e-05\n",
            "Epoch 33/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.6361e-04 - val_loss: 0.0011 - learning_rate: 6.2500e-05\n",
            "Epoch 34/60\n",
            "\u001b[1m19/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.5317e-04\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.5236e-04 - val_loss: 0.0011 - learning_rate: 6.2500e-05\n",
            "Epoch 35/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.4989e-04 - val_loss: 0.0011 - learning_rate: 3.1250e-05\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "✅ 第 4 个滑动窗口训练完成\n",
            "Epoch 1/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.0612 - val_loss: 0.0469 - learning_rate: 0.0010\n",
            "Epoch 2/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0430 - val_loss: 0.0334 - learning_rate: 0.0010\n",
            "Epoch 3/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0309 - val_loss: 0.0241 - learning_rate: 0.0010\n",
            "Epoch 4/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0221 - val_loss: 0.0176 - learning_rate: 0.0010\n",
            "Epoch 5/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0154 - val_loss: 0.0137 - learning_rate: 0.0010\n",
            "Epoch 6/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0107 - val_loss: 0.0106 - learning_rate: 0.0010\n",
            "Epoch 7/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0074 - val_loss: 0.0077 - learning_rate: 0.0010\n",
            "Epoch 8/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0051 - val_loss: 0.0064 - learning_rate: 0.0010\n",
            "Epoch 9/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0036 - val_loss: 0.0047 - learning_rate: 0.0010\n",
            "Epoch 10/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0025 - val_loss: 0.0043 - learning_rate: 0.0010\n",
            "Epoch 11/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0018 - val_loss: 0.0035 - learning_rate: 0.0010\n",
            "Epoch 12/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0012 - val_loss: 0.0035 - learning_rate: 0.0010\n",
            "Epoch 13/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.6830e-04 - val_loss: 0.0028 - learning_rate: 0.0010\n",
            "Epoch 14/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 7.6065e-04 - val_loss: 0.0024 - learning_rate: 0.0010\n",
            "Epoch 15/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.4386e-04 - val_loss: 0.0024 - learning_rate: 0.0010\n",
            "Epoch 16/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.9908e-04 - val_loss: 0.0029 - learning_rate: 0.0010\n",
            "Epoch 17/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.1312e-04 - val_loss: 0.0035 - learning_rate: 0.0010\n",
            "Epoch 18/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.1579e-04 - val_loss: 0.0022 - learning_rate: 0.0010\n",
            "Epoch 19/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.9378e-04 - val_loss: 0.0031 - learning_rate: 0.0010\n",
            "Epoch 20/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.6574e-04 - val_loss: 0.0022 - learning_rate: 0.0010\n",
            "Epoch 21/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.4644e-04 - val_loss: 0.0022 - learning_rate: 0.0010\n",
            "Epoch 22/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.4121e-04\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.4186e-04 - val_loss: 0.0026 - learning_rate: 0.0010\n",
            "Epoch 23/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.2721e-04 - val_loss: 0.0022 - learning_rate: 5.0000e-04\n",
            "Epoch 24/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.9147e-04 - val_loss: 0.0015 - learning_rate: 5.0000e-04\n",
            "Epoch 25/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.1929e-04 - val_loss: 0.0012 - learning_rate: 5.0000e-04\n",
            "Epoch 26/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.8592e-04 - val_loss: 9.7445e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 27/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.6648e-04 - val_loss: 8.8249e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 28/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.7179e-04 - val_loss: 8.9108e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 29/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.2230e-04 - val_loss: 0.0026 - learning_rate: 5.0000e-04\n",
            "Epoch 30/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.1281e-04\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.1244e-04 - val_loss: 0.0026 - learning_rate: 5.0000e-04\n",
            "Epoch 31/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.5782e-04 - val_loss: 0.0026 - learning_rate: 2.5000e-04\n",
            "Epoch 32/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.0897e-04 - val_loss: 0.0020 - learning_rate: 2.5000e-04\n",
            "Epoch 33/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.5987e-04 - val_loss: 0.0013 - learning_rate: 2.5000e-04\n",
            "Epoch 34/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.9192e-04\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.9237e-04 - val_loss: 9.7549e-04 - learning_rate: 2.5000e-04\n",
            "Epoch 35/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 1.8964e-04 - val_loss: 9.5691e-04 - learning_rate: 1.2500e-04\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 209ms/step\n",
            "✅ 第 5 个滑动窗口训练完成\n",
            "Epoch 1/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0620 - val_loss: 0.0469 - learning_rate: 0.0010\n",
            "Epoch 2/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0435 - val_loss: 0.0333 - learning_rate: 0.0010\n",
            "Epoch 3/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0312 - val_loss: 0.0239 - learning_rate: 0.0010\n",
            "Epoch 4/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0223 - val_loss: 0.0168 - learning_rate: 0.0010\n",
            "Epoch 5/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0158 - val_loss: 0.0118 - learning_rate: 0.0010\n",
            "Epoch 6/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0112 - val_loss: 0.0083 - learning_rate: 0.0010\n",
            "Epoch 7/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0079 - val_loss: 0.0058 - learning_rate: 0.0010\n",
            "Epoch 8/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0055 - val_loss: 0.0040 - learning_rate: 0.0010\n",
            "Epoch 9/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0040 - val_loss: 0.0028 - learning_rate: 0.0010\n",
            "Epoch 10/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0028 - val_loss: 0.0020 - learning_rate: 0.0010\n",
            "Epoch 11/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0021 - val_loss: 0.0013 - learning_rate: 0.0010\n",
            "Epoch 12/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0015 - val_loss: 0.0012 - learning_rate: 0.0010\n",
            "Epoch 13/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0012 - val_loss: 5.8417e-04 - learning_rate: 0.0010\n",
            "Epoch 14/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 6.6555e-04 - val_loss: 3.5880e-04 - learning_rate: 0.0010\n",
            "Epoch 15/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 5.5141e-04 - val_loss: 2.6835e-04 - learning_rate: 0.0010\n",
            "Epoch 16/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 4.2525e-04 - val_loss: 2.1011e-04 - learning_rate: 0.0010\n",
            "Epoch 17/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.0049e-04 - val_loss: 1.5878e-04 - learning_rate: 0.0010\n",
            "Epoch 18/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.9368e-04 - val_loss: 1.6742e-04 - learning_rate: 0.0010\n",
            "Epoch 19/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.6525e-04 - val_loss: 1.1354e-04 - learning_rate: 0.0010\n",
            "Epoch 20/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.6675e-04\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.6486e-04 - val_loss: 1.1014e-04 - learning_rate: 0.0010\n",
            "Epoch 21/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.1046e-04 - val_loss: 1.2990e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 22/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.8160e-04 - val_loss: 9.7998e-05 - learning_rate: 5.0000e-04\n",
            "Epoch 23/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.6104e-04 - val_loss: 1.0428e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 24/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.7656e-04 - val_loss: 9.3212e-05 - learning_rate: 5.0000e-04\n",
            "Epoch 25/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.6578e-04 - val_loss: 8.9666e-05 - learning_rate: 5.0000e-04\n",
            "Epoch 26/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5415e-04\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5454e-04 - val_loss: 1.4081e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 27/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 1.6021e-04 - val_loss: 1.0184e-04 - learning_rate: 2.5000e-04\n",
            "Epoch 28/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3508e-04 - val_loss: 1.1648e-04 - learning_rate: 2.5000e-04\n",
            "Epoch 29/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5008e-04 - val_loss: 2.3353e-04 - learning_rate: 2.5000e-04\n",
            "Epoch 30/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4227e-04\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4215e-04 - val_loss: 8.2174e-05 - learning_rate: 2.5000e-04\n",
            "Epoch 31/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4252e-04 - val_loss: 9.3288e-05 - learning_rate: 1.2500e-04\n",
            "Epoch 32/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.4062e-04 - val_loss: 9.6002e-05 - learning_rate: 1.2500e-04\n",
            "Epoch 33/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.2946e-04 - val_loss: 8.9030e-05 - learning_rate: 1.2500e-04\n",
            "Epoch 34/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3213e-04\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.3249e-04 - val_loss: 8.0450e-05 - learning_rate: 1.2500e-04\n",
            "Epoch 35/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.4397e-04 - val_loss: 9.8001e-05 - learning_rate: 6.2500e-05\n",
            "Epoch 36/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2676e-04 - val_loss: 9.3887e-05 - learning_rate: 6.2500e-05\n",
            "Epoch 37/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.2361e-04 - val_loss: 1.1017e-04 - learning_rate: 6.2500e-05\n",
            "Epoch 38/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.4053e-04\n",
            "Epoch 38: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.3940e-04 - val_loss: 1.0141e-04 - learning_rate: 6.2500e-05\n",
            "Epoch 39/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.3579e-04 - val_loss: 9.5471e-05 - learning_rate: 3.1250e-05\n",
            "Epoch 40/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2166e-04 - val_loss: 9.7879e-05 - learning_rate: 3.1250e-05\n",
            "Epoch 41/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2452e-04 - val_loss: 1.0190e-04 - learning_rate: 3.1250e-05\n",
            "Epoch 42/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3320e-04\n",
            "Epoch 42: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3270e-04 - val_loss: 9.2071e-05 - learning_rate: 3.1250e-05\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step\n",
            "✅ 第 6 个滑动窗口训练完成\n",
            "Epoch 1/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0623 - val_loss: 0.0478 - learning_rate: 0.0010\n",
            "Epoch 2/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0435 - val_loss: 0.0345 - learning_rate: 0.0010\n",
            "Epoch 3/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0313 - val_loss: 0.0245 - learning_rate: 0.0010\n",
            "Epoch 4/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0224 - val_loss: 0.0177 - learning_rate: 0.0010\n",
            "Epoch 5/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0158 - val_loss: 0.0131 - learning_rate: 0.0010\n",
            "Epoch 6/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0113 - val_loss: 0.0088 - learning_rate: 0.0010\n",
            "Epoch 7/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0079 - val_loss: 0.0067 - learning_rate: 0.0010\n",
            "Epoch 8/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0056 - val_loss: 0.0047 - learning_rate: 0.0010\n",
            "Epoch 9/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0040 - val_loss: 0.0034 - learning_rate: 0.0010\n",
            "Epoch 10/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0029 - val_loss: 0.0028 - learning_rate: 0.0010\n",
            "Epoch 11/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0021 - val_loss: 0.0018 - learning_rate: 0.0010\n",
            "Epoch 12/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0017 - val_loss: 0.0019 - learning_rate: 0.0010\n",
            "Epoch 13/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0013 - val_loss: 0.0016 - learning_rate: 0.0010\n",
            "Epoch 14/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0013 - val_loss: 0.0015 - learning_rate: 0.0010\n",
            "Epoch 15/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0011 - val_loss: 2.9225e-04 - learning_rate: 0.0010\n",
            "Epoch 16/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.0648e-04 - val_loss: 0.0017 - learning_rate: 0.0010\n",
            "Epoch 17/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.6985e-04 - val_loss: 5.9607e-04 - learning_rate: 0.0010\n",
            "Epoch 18/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.7524e-04 - val_loss: 7.2532e-04 - learning_rate: 0.0010\n",
            "Epoch 19/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.1645e-04 - val_loss: 1.9021e-04 - learning_rate: 0.0010\n",
            "Epoch 20/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.2850e-04 - val_loss: 2.1965e-04 - learning_rate: 0.0010\n",
            "Epoch 21/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.0012e-04 - val_loss: 1.5786e-04 - learning_rate: 0.0010\n",
            "Epoch 22/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.3735e-04 - val_loss: 2.7049e-04 - learning_rate: 0.0010\n",
            "Epoch 23/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.2860e-04\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.2921e-04 - val_loss: 1.4939e-04 - learning_rate: 0.0010\n",
            "Epoch 24/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.8814e-04 - val_loss: 1.6006e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 25/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.9962e-04 - val_loss: 1.5308e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 26/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.8176e-04 - val_loss: 1.1142e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 27/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7050e-04\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.7143e-04 - val_loss: 1.1463e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 28/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.7305e-04 - val_loss: 1.1660e-04 - learning_rate: 2.5000e-04\n",
            "Epoch 29/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.8117e-04 - val_loss: 1.0715e-04 - learning_rate: 2.5000e-04\n",
            "Epoch 30/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6344e-04 - val_loss: 1.0205e-04 - learning_rate: 2.5000e-04\n",
            "Epoch 31/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6222e-04\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.6232e-04 - val_loss: 1.0451e-04 - learning_rate: 2.5000e-04\n",
            "Epoch 32/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5346e-04 - val_loss: 9.6816e-05 - learning_rate: 1.2500e-04\n",
            "Epoch 33/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5302e-04 - val_loss: 1.0106e-04 - learning_rate: 1.2500e-04\n",
            "Epoch 34/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.5372e-04 - val_loss: 9.0828e-05 - learning_rate: 1.2500e-04\n",
            "Epoch 35/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5039e-04\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.5036e-04 - val_loss: 9.0284e-05 - learning_rate: 1.2500e-04\n",
            "Epoch 36/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.3977e-04 - val_loss: 8.9265e-05 - learning_rate: 6.2500e-05\n",
            "Epoch 37/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.4079e-04 - val_loss: 9.0678e-05 - learning_rate: 6.2500e-05\n",
            "Epoch 38/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4686e-04 - val_loss: 1.0058e-04 - learning_rate: 6.2500e-05\n",
            "Epoch 39/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3760e-04 - val_loss: 9.9166e-05 - learning_rate: 6.2500e-05\n",
            "Epoch 40/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3801e-04\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3858e-04 - val_loss: 9.2827e-05 - learning_rate: 6.2500e-05\n",
            "Epoch 41/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.4100e-04 - val_loss: 8.2593e-05 - learning_rate: 3.1250e-05\n",
            "Epoch 42/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.4936e-04 - val_loss: 8.4444e-05 - learning_rate: 3.1250e-05\n",
            "Epoch 43/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4720e-04 - val_loss: 9.0140e-05 - learning_rate: 3.1250e-05\n",
            "Epoch 44/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3888e-04\n",
            "Epoch 44: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.3862e-04 - val_loss: 8.0960e-05 - learning_rate: 3.1250e-05\n",
            "Epoch 45/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4600e-04 - val_loss: 8.5689e-05 - learning_rate: 1.5625e-05\n",
            "Epoch 46/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3019e-04 - val_loss: 8.5857e-05 - learning_rate: 1.5625e-05\n",
            "Epoch 47/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3852e-04 - val_loss: 9.1828e-05 - learning_rate: 1.5625e-05\n",
            "Epoch 48/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2871e-04\n",
            "Epoch 48: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2945e-04 - val_loss: 8.6518e-05 - learning_rate: 1.5625e-05\n",
            "Epoch 49/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3884e-04 - val_loss: 8.8615e-05 - learning_rate: 7.8125e-06\n",
            "Epoch 50/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 1.4087e-04 - val_loss: 8.8252e-05 - learning_rate: 7.8125e-06\n",
            "Epoch 51/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4387e-04 - val_loss: 8.7231e-05 - learning_rate: 7.8125e-06\n",
            "Epoch 52/60\n",
            "\u001b[1m20/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4046e-04\n",
            "Epoch 52: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.4059e-04 - val_loss: 8.6282e-05 - learning_rate: 7.8125e-06\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step\n",
            "✅ 第 7 个滑动窗口训练完成\n",
            "Epoch 1/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - loss: 0.0635 - val_loss: 0.0466 - learning_rate: 0.0010\n",
            "Epoch 2/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0435 - val_loss: 0.0334 - learning_rate: 0.0010\n",
            "Epoch 3/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0313 - val_loss: 0.0237 - learning_rate: 0.0010\n",
            "Epoch 4/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0223 - val_loss: 0.0167 - learning_rate: 0.0010\n",
            "Epoch 5/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0159 - val_loss: 0.0117 - learning_rate: 0.0010\n",
            "Epoch 6/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0111 - val_loss: 0.0081 - learning_rate: 0.0010\n",
            "Epoch 7/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0078 - val_loss: 0.0055 - learning_rate: 0.0010\n",
            "Epoch 8/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0054 - val_loss: 0.0038 - learning_rate: 0.0010\n",
            "Epoch 9/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0038 - val_loss: 0.0026 - learning_rate: 0.0010\n",
            "Epoch 10/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0028 - val_loss: 0.0017 - learning_rate: 0.0010\n",
            "Epoch 11/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0019 - val_loss: 0.0012 - learning_rate: 0.0010\n",
            "Epoch 12/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0015 - val_loss: 8.7176e-04 - learning_rate: 0.0010\n",
            "Epoch 13/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0012 - val_loss: 6.6891e-04 - learning_rate: 0.0010\n",
            "Epoch 14/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.6686e-04 - val_loss: 4.8895e-04 - learning_rate: 0.0010\n",
            "Epoch 15/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.7860e-04 - val_loss: 3.8762e-04 - learning_rate: 0.0010\n",
            "Epoch 16/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.3733e-04 - val_loss: 3.5690e-04 - learning_rate: 0.0010\n",
            "Epoch 17/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.2963e-04 - val_loss: 2.6665e-04 - learning_rate: 0.0010\n",
            "Epoch 18/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.5746e-04 - val_loss: 1.7430e-04 - learning_rate: 0.0010\n",
            "Epoch 19/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.1531e-04 - val_loss: 2.0983e-04 - learning_rate: 0.0010\n",
            "Epoch 20/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.0226e-04 - val_loss: 1.0617e-04 - learning_rate: 0.0010\n",
            "Epoch 21/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.4405e-04 - val_loss: 9.7704e-05 - learning_rate: 0.0010\n",
            "Epoch 22/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 1.2154e-04 - val_loss: 7.8421e-05 - learning_rate: 0.0010\n",
            "Epoch 23/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.4015e-04 - val_loss: 9.0716e-05 - learning_rate: 0.0010\n",
            "Epoch 24/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2301e-04\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.2356e-04 - val_loss: 5.0502e-05 - learning_rate: 0.0010\n",
            "Epoch 25/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.3771e-04 - val_loss: 1.5441e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 26/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.6818e-04 - val_loss: 1.9585e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 27/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.7463e-04 - val_loss: 9.8380e-05 - learning_rate: 5.0000e-04\n",
            "Epoch 28/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4725e-04\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.4715e-04 - val_loss: 9.0368e-05 - learning_rate: 5.0000e-04\n",
            "Epoch 29/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.3146e-04 - val_loss: 9.6100e-05 - learning_rate: 2.5000e-04\n",
            "Epoch 30/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.2773e-04 - val_loss: 6.7714e-05 - learning_rate: 2.5000e-04\n",
            "Epoch 31/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2417e-04 - val_loss: 1.2326e-04 - learning_rate: 2.5000e-04\n",
            "Epoch 32/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2787e-04\n",
            "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2830e-04 - val_loss: 8.9379e-05 - learning_rate: 2.5000e-04\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "✅ 第 8 个滑动窗口训练完成\n",
            "Epoch 1/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0644 - val_loss: 0.0566 - learning_rate: 0.0010\n",
            "Epoch 2/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0435 - val_loss: 0.0421 - learning_rate: 0.0010\n",
            "Epoch 3/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0311 - val_loss: 0.0328 - learning_rate: 0.0010\n",
            "Epoch 4/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0221 - val_loss: 0.0256 - learning_rate: 0.0010\n",
            "Epoch 5/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0156 - val_loss: 0.0197 - learning_rate: 0.0010\n",
            "Epoch 6/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0109 - val_loss: 0.0158 - learning_rate: 0.0010\n",
            "Epoch 7/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0076 - val_loss: 0.0138 - learning_rate: 0.0010\n",
            "Epoch 8/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0052 - val_loss: 0.0121 - learning_rate: 0.0010\n",
            "Epoch 9/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0036 - val_loss: 0.0110 - learning_rate: 0.0010\n",
            "Epoch 10/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0025 - val_loss: 0.0102 - learning_rate: 0.0010\n",
            "Epoch 11/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0018 - val_loss: 0.0099 - learning_rate: 0.0010\n",
            "Epoch 12/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0013 - val_loss: 0.0087 - learning_rate: 0.0010\n",
            "Epoch 13/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.4637e-04 - val_loss: 0.0089 - learning_rate: 0.0010\n",
            "Epoch 14/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 7.4442e-04 - val_loss: 0.0089 - learning_rate: 0.0010\n",
            "Epoch 15/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.5302e-04 - val_loss: 0.0087 - learning_rate: 0.0010\n",
            "Epoch 16/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.0464e-04 - val_loss: 0.0084 - learning_rate: 0.0010\n",
            "Epoch 17/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.9657e-04 - val_loss: 0.0091 - learning_rate: 0.0010\n",
            "Epoch 18/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.6028e-04 - val_loss: 0.0087 - learning_rate: 0.0010\n",
            "Epoch 19/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 4.4516e-04 - val_loss: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 20/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.3885e-04\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.3825e-04 - val_loss: 0.0093 - learning_rate: 0.0010\n",
            "Epoch 21/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.7177e-04 - val_loss: 0.0085 - learning_rate: 5.0000e-04\n",
            "Epoch 22/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.8408e-04 - val_loss: 0.0089 - learning_rate: 5.0000e-04\n",
            "Epoch 23/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.0641e-04 - val_loss: 0.0086 - learning_rate: 5.0000e-04\n",
            "Epoch 24/60\n",
            "\u001b[1m20/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.0520e-04\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 4.0784e-04 - val_loss: 0.0088 - learning_rate: 5.0000e-04\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step\n",
            "✅ 第 9 个滑动窗口训练完成\n",
            "Epoch 1/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0713 - val_loss: 0.0935 - learning_rate: 0.0010\n",
            "Epoch 2/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0466 - val_loss: 0.0747 - learning_rate: 0.0010\n",
            "Epoch 3/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0343 - val_loss: 0.0583 - learning_rate: 0.0010\n",
            "Epoch 4/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0247 - val_loss: 0.0267 - learning_rate: 0.0010\n",
            "Epoch 5/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0177 - val_loss: 0.0237 - learning_rate: 0.0010\n",
            "Epoch 6/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0118 - val_loss: 0.0158 - learning_rate: 0.0010\n",
            "Epoch 7/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0081 - val_loss: 0.0148 - learning_rate: 0.0010\n",
            "Epoch 8/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0055 - val_loss: 0.0133 - learning_rate: 0.0010\n",
            "Epoch 9/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0038 - val_loss: 0.0128 - learning_rate: 0.0010\n",
            "Epoch 10/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0027 - val_loss: 0.0142 - learning_rate: 0.0010\n",
            "Epoch 11/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0018 - val_loss: 0.0114 - learning_rate: 0.0010\n",
            "Epoch 12/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0014 - val_loss: 0.0094 - learning_rate: 0.0010\n",
            "Epoch 13/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 9.4328e-04 - val_loss: 0.0105 - learning_rate: 0.0010\n",
            "Epoch 14/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 7.2009e-04 - val_loss: 0.0079 - learning_rate: 0.0010\n",
            "Epoch 15/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.9271e-04 - val_loss: 0.0105 - learning_rate: 0.0010\n",
            "Epoch 16/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 6.6318e-04 - val_loss: 0.0073 - learning_rate: 0.0010\n",
            "Epoch 17/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.1900e-04 - val_loss: 0.0080 - learning_rate: 0.0010\n",
            "Epoch 18/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.8973e-04 - val_loss: 0.0055 - learning_rate: 0.0010\n",
            "Epoch 19/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.0199e-04 - val_loss: 0.0048 - learning_rate: 0.0010\n",
            "Epoch 20/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 2.6167e-04 - val_loss: 0.0068 - learning_rate: 0.0010\n",
            "Epoch 21/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.3538e-04 - val_loss: 0.0062 - learning_rate: 0.0010\n",
            "Epoch 22/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.5701e-04 - val_loss: 0.0107 - learning_rate: 0.0010\n",
            "Epoch 23/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.3603e-04\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.3377e-04 - val_loss: 0.0067 - learning_rate: 0.0010\n",
            "Epoch 24/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.7525e-04 - val_loss: 0.0064 - learning_rate: 5.0000e-04\n",
            "Epoch 25/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.9135e-04 - val_loss: 0.0052 - learning_rate: 5.0000e-04\n",
            "Epoch 26/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 1.9345e-04 - val_loss: 0.0084 - learning_rate: 5.0000e-04\n",
            "Epoch 27/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.1631e-04\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.1483e-04 - val_loss: 0.0088 - learning_rate: 5.0000e-04\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step\n",
            "✅ 第 10 个滑动窗口训练完成\n",
            "Epoch 1/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.0954 - val_loss: 0.0761 - learning_rate: 0.0010\n",
            "Epoch 2/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0576 - val_loss: 0.0579 - learning_rate: 0.0010\n",
            "Epoch 3/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0427 - val_loss: 0.0287 - learning_rate: 0.0010\n",
            "Epoch 4/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0274 - val_loss: 0.0214 - learning_rate: 0.0010\n",
            "Epoch 5/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0219 - val_loss: 0.0195 - learning_rate: 0.0010\n",
            "Epoch 6/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0160 - val_loss: 0.0122 - learning_rate: 0.0010\n",
            "Epoch 7/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0114 - val_loss: 0.0111 - learning_rate: 0.0010\n",
            "Epoch 8/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0097 - val_loss: 0.0116 - learning_rate: 0.0010\n",
            "Epoch 9/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0097 - val_loss: 0.0061 - learning_rate: 0.0010\n",
            "Epoch 10/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0055 - val_loss: 0.0037 - learning_rate: 0.0010\n",
            "Epoch 11/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0041 - val_loss: 0.0033 - learning_rate: 0.0010\n",
            "Epoch 12/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0031 - val_loss: 0.0023 - learning_rate: 0.0010\n",
            "Epoch 13/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0024 - val_loss: 0.0021 - learning_rate: 0.0010\n",
            "Epoch 14/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0020 - val_loss: 0.0017 - learning_rate: 0.0010\n",
            "Epoch 15/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0018 - val_loss: 0.0013 - learning_rate: 0.0010\n",
            "Epoch 16/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0014 - val_loss: 8.5907e-04 - learning_rate: 0.0010\n",
            "Epoch 17/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0013 - val_loss: 9.1572e-04 - learning_rate: 0.0010\n",
            "Epoch 18/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 9.0703e-04 - val_loss: 0.0011 - learning_rate: 0.0010\n",
            "Epoch 19/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 7.4001e-04 - val_loss: 0.0011 - learning_rate: 0.0010\n",
            "Epoch 20/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.5073e-04\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 7.5001e-04 - val_loss: 0.0011 - learning_rate: 0.0010\n",
            "Epoch 21/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 6.7299e-04 - val_loss: 0.0019 - learning_rate: 5.0000e-04\n",
            "Epoch 22/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 6.6281e-04 - val_loss: 0.0014 - learning_rate: 5.0000e-04\n",
            "Epoch 23/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 5.7923e-04 - val_loss: 0.0016 - learning_rate: 5.0000e-04\n",
            "Epoch 24/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.8447e-04\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 4.8557e-04 - val_loss: 0.0017 - learning_rate: 5.0000e-04\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step\n",
            "✅ 第 11 个滑动窗口训练完成\n",
            "Epoch 1/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.1117 - val_loss: 0.0604 - learning_rate: 0.0010\n",
            "Epoch 2/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0535 - val_loss: 0.0427 - learning_rate: 0.0010\n",
            "Epoch 3/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0403 - val_loss: 0.0297 - learning_rate: 0.0010\n",
            "Epoch 4/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0293 - val_loss: 0.0227 - learning_rate: 0.0010\n",
            "Epoch 5/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0223 - val_loss: 0.0176 - learning_rate: 0.0010\n",
            "Epoch 6/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0170 - val_loss: 0.0139 - learning_rate: 0.0010\n",
            "Epoch 7/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0130 - val_loss: 0.0099 - learning_rate: 0.0010\n",
            "Epoch 8/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0101 - val_loss: 0.0088 - learning_rate: 0.0010\n",
            "Epoch 9/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0075 - val_loss: 0.0058 - learning_rate: 0.0010\n",
            "Epoch 10/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0058 - val_loss: 0.0046 - learning_rate: 0.0010\n",
            "Epoch 11/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0044 - val_loss: 0.0037 - learning_rate: 0.0010\n",
            "Epoch 12/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0034 - val_loss: 0.0035 - learning_rate: 0.0010\n",
            "Epoch 13/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0026 - val_loss: 0.0031 - learning_rate: 0.0010\n",
            "Epoch 14/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0022 - val_loss: 0.0038 - learning_rate: 0.0010\n",
            "Epoch 15/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0019 - val_loss: 0.0042 - learning_rate: 0.0010\n",
            "Epoch 16/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0016 - val_loss: 0.0039 - learning_rate: 0.0010\n",
            "Epoch 17/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0014\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0014 - val_loss: 0.0033 - learning_rate: 0.0010\n",
            "Epoch 18/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0010 - val_loss: 0.0029 - learning_rate: 5.0000e-04\n",
            "Epoch 19/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.5922e-04 - val_loss: 0.0038 - learning_rate: 5.0000e-04\n",
            "Epoch 20/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 9.9284e-04 - val_loss: 0.0023 - learning_rate: 5.0000e-04\n",
            "Epoch 21/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.3201e-04 - val_loss: 0.0021 - learning_rate: 5.0000e-04\n",
            "Epoch 22/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 8.1728e-04 - val_loss: 0.0017 - learning_rate: 5.0000e-04\n",
            "Epoch 23/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.0643e-04 - val_loss: 0.0024 - learning_rate: 5.0000e-04\n",
            "Epoch 24/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 6.9981e-04 - val_loss: 0.0019 - learning_rate: 5.0000e-04\n",
            "Epoch 25/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.8025e-04 - val_loss: 0.0025 - learning_rate: 5.0000e-04\n",
            "Epoch 26/60\n",
            "\u001b[1m20/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.0572e-04\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 6.0604e-04 - val_loss: 0.0036 - learning_rate: 5.0000e-04\n",
            "Epoch 27/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 6.6442e-04 - val_loss: 0.0028 - learning_rate: 2.5000e-04\n",
            "Epoch 28/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 5.7699e-04 - val_loss: 0.0018 - learning_rate: 2.5000e-04\n",
            "Epoch 29/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.7168e-04 - val_loss: 0.0021 - learning_rate: 2.5000e-04\n",
            "Epoch 30/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.4367e-04\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 5.4386e-04 - val_loss: 0.0017 - learning_rate: 2.5000e-04\n",
            "Epoch 31/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.3617e-04 - val_loss: 0.0024 - learning_rate: 1.2500e-04\n",
            "Epoch 32/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 5.5158e-04 - val_loss: 0.0014 - learning_rate: 1.2500e-04\n",
            "Epoch 33/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 5.2934e-04 - val_loss: 0.0020 - learning_rate: 1.2500e-04\n",
            "Epoch 34/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 5.1428e-04 - val_loss: 0.0020 - learning_rate: 1.2500e-04\n",
            "Epoch 35/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 5.0840e-04 - val_loss: 0.0018 - learning_rate: 1.2500e-04\n",
            "Epoch 36/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.4213e-04\n",
            "Epoch 36: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.3772e-04 - val_loss: 0.0016 - learning_rate: 1.2500e-04\n",
            "Epoch 37/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.5002e-04 - val_loss: 0.0018 - learning_rate: 6.2500e-05\n",
            "Epoch 38/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.8368e-04 - val_loss: 0.0020 - learning_rate: 6.2500e-05\n",
            "Epoch 39/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.4574e-04 - val_loss: 0.0015 - learning_rate: 6.2500e-05\n",
            "Epoch 40/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.7248e-04\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.7288e-04 - val_loss: 0.0018 - learning_rate: 6.2500e-05\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "✅ 第 12 个滑动窗口训练完成\n",
            "Epoch 1/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - loss: 0.1249 - val_loss: 0.0580 - learning_rate: 0.0010\n",
            "Epoch 2/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0529 - val_loss: 0.0415 - learning_rate: 0.0010\n",
            "Epoch 3/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0398 - val_loss: 0.0327 - learning_rate: 0.0010\n",
            "Epoch 4/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0313 - val_loss: 0.0258 - learning_rate: 0.0010\n",
            "Epoch 5/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0248 - val_loss: 0.0204 - learning_rate: 0.0010\n",
            "Epoch 6/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0194 - val_loss: 0.0168 - learning_rate: 0.0010\n",
            "Epoch 7/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0148 - val_loss: 0.0125 - learning_rate: 0.0010\n",
            "Epoch 8/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0116 - val_loss: 0.0088 - learning_rate: 0.0010\n",
            "Epoch 9/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0092 - val_loss: 0.0075 - learning_rate: 0.0010\n",
            "Epoch 10/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0071 - val_loss: 0.0063 - learning_rate: 0.0010\n",
            "Epoch 11/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0056 - val_loss: 0.0053 - learning_rate: 0.0010\n",
            "Epoch 12/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0044 - val_loss: 0.0038 - learning_rate: 0.0010\n",
            "Epoch 13/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0038 - val_loss: 0.0046 - learning_rate: 0.0010\n",
            "Epoch 14/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0032 - val_loss: 0.0024 - learning_rate: 0.0010\n",
            "Epoch 15/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0026 - val_loss: 0.0020 - learning_rate: 0.0010\n",
            "Epoch 16/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0022 - val_loss: 0.0025 - learning_rate: 0.0010\n",
            "Epoch 17/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0018 - val_loss: 0.0014 - learning_rate: 0.0010\n",
            "Epoch 18/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0016 - val_loss: 0.0012 - learning_rate: 0.0010\n",
            "Epoch 19/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0014 - val_loss: 0.0011 - learning_rate: 0.0010\n",
            "Epoch 20/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0013 - val_loss: 9.0549e-04 - learning_rate: 0.0010\n",
            "Epoch 21/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0011 - val_loss: 8.1478e-04 - learning_rate: 0.0010\n",
            "Epoch 22/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.7142e-04 - val_loss: 7.7697e-04 - learning_rate: 0.0010\n",
            "Epoch 23/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0010 - val_loss: 0.0012 - learning_rate: 0.0010\n",
            "Epoch 24/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.0641e-04 - val_loss: 0.0014 - learning_rate: 0.0010\n",
            "Epoch 25/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 7.3313e-04 - val_loss: 6.1537e-04 - learning_rate: 0.0010\n",
            "Epoch 26/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.2738e-04 - val_loss: 0.0012 - learning_rate: 0.0010\n",
            "Epoch 27/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 6.9672e-04 - val_loss: 6.5737e-04 - learning_rate: 0.0010\n",
            "Epoch 28/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.6390e-04 - val_loss: 5.4791e-04 - learning_rate: 0.0010\n",
            "Epoch 29/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.5991e-04 - val_loss: 4.3574e-04 - learning_rate: 0.0010\n",
            "Epoch 30/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.2013e-04 - val_loss: 8.8744e-04 - learning_rate: 0.0010\n",
            "Epoch 31/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 5.2442e-04 - val_loss: 3.9427e-04 - learning_rate: 0.0010\n",
            "Epoch 32/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 4.8147e-04 - val_loss: 4.5551e-04 - learning_rate: 0.0010\n",
            "Epoch 33/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.3651e-04\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 5.3642e-04 - val_loss: 3.8579e-04 - learning_rate: 0.0010\n",
            "Epoch 34/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 4.3657e-04 - val_loss: 3.7286e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 35/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.1523e-04 - val_loss: 3.3982e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 36/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.9609e-04 - val_loss: 3.6825e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 37/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.6054e-04\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.6249e-04 - val_loss: 3.7721e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 38/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.8478e-04 - val_loss: 3.1487e-04 - learning_rate: 2.5000e-04\n",
            "Epoch 39/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.4152e-04 - val_loss: 3.1848e-04 - learning_rate: 2.5000e-04\n",
            "Epoch 40/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.3102e-04 - val_loss: 3.2907e-04 - learning_rate: 2.5000e-04\n",
            "Epoch 41/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.2477e-04 - val_loss: 3.0404e-04 - learning_rate: 2.5000e-04\n",
            "Epoch 42/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.4336e-04\n",
            "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.4374e-04 - val_loss: 3.2268e-04 - learning_rate: 2.5000e-04\n",
            "Epoch 43/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.2432e-04 - val_loss: 3.0301e-04 - learning_rate: 1.2500e-04\n",
            "Epoch 44/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.1845e-04 - val_loss: 3.3001e-04 - learning_rate: 1.2500e-04\n",
            "Epoch 45/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.2700e-04 - val_loss: 3.3358e-04 - learning_rate: 1.2500e-04\n",
            "Epoch 46/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.3153e-04\n",
            "Epoch 46: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.3271e-04 - val_loss: 3.0674e-04 - learning_rate: 1.2500e-04\n",
            "Epoch 47/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 3.0675e-04 - val_loss: 3.0712e-04 - learning_rate: 6.2500e-05\n",
            "Epoch 48/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.3079e-04 - val_loss: 2.9442e-04 - learning_rate: 6.2500e-05\n",
            "Epoch 49/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.3112e-04 - val_loss: 2.9498e-04 - learning_rate: 6.2500e-05\n",
            "Epoch 50/60\n",
            "\u001b[1m19/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.2295e-04\n",
            "Epoch 50: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.2295e-04 - val_loss: 2.9198e-04 - learning_rate: 6.2500e-05\n",
            "Epoch 51/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.2303e-04 - val_loss: 3.1334e-04 - learning_rate: 3.1250e-05\n",
            "Epoch 52/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.9920e-04 - val_loss: 3.3797e-04 - learning_rate: 3.1250e-05\n",
            "Epoch 53/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.3065e-04 - val_loss: 3.0514e-04 - learning_rate: 3.1250e-05\n",
            "Epoch 54/60\n",
            "\u001b[1m20/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.1070e-04\n",
            "Epoch 54: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 3.1035e-04 - val_loss: 3.1395e-04 - learning_rate: 3.1250e-05\n",
            "Epoch 55/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 3.1950e-04 - val_loss: 3.0576e-04 - learning_rate: 1.5625e-05\n",
            "Epoch 56/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 2.8763e-04 - val_loss: 3.1165e-04 - learning_rate: 1.5625e-05\n",
            "Epoch 57/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 3.3188e-04 - val_loss: 3.0804e-04 - learning_rate: 1.5625e-05\n",
            "Epoch 58/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.2286e-04\n",
            "Epoch 58: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.2323e-04 - val_loss: 3.0744e-04 - learning_rate: 1.5625e-05\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step\n",
            "✅ 第 13 个滑动窗口训练完成\n",
            "Epoch 1/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - loss: 0.1313 - val_loss: 0.0618 - learning_rate: 0.0010\n",
            "Epoch 2/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0514 - val_loss: 0.0431 - learning_rate: 0.0010\n",
            "Epoch 3/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0405 - val_loss: 0.0358 - learning_rate: 0.0010\n",
            "Epoch 4/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0325 - val_loss: 0.0292 - learning_rate: 0.0010\n",
            "Epoch 5/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0261 - val_loss: 0.0230 - learning_rate: 0.0010\n",
            "Epoch 6/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0207 - val_loss: 0.0189 - learning_rate: 0.0010\n",
            "Epoch 7/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0165 - val_loss: 0.0163 - learning_rate: 0.0010\n",
            "Epoch 8/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0133 - val_loss: 0.0124 - learning_rate: 0.0010\n",
            "Epoch 9/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0105 - val_loss: 0.0109 - learning_rate: 0.0010\n",
            "Epoch 10/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0086 - val_loss: 0.0081 - learning_rate: 0.0010\n",
            "Epoch 11/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0070 - val_loss: 0.0062 - learning_rate: 0.0010\n",
            "Epoch 12/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0059 - val_loss: 0.0064 - learning_rate: 0.0010\n",
            "Epoch 13/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0049 - val_loss: 0.0040 - learning_rate: 0.0010\n",
            "Epoch 14/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0041 - val_loss: 0.0028 - learning_rate: 0.0010\n",
            "Epoch 15/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0032 - val_loss: 0.0025 - learning_rate: 0.0010\n",
            "Epoch 16/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0024 - val_loss: 0.0019 - learning_rate: 0.0010\n",
            "Epoch 17/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0023 - val_loss: 0.0018 - learning_rate: 0.0010\n",
            "Epoch 18/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0017 - val_loss: 0.0024 - learning_rate: 0.0010\n",
            "Epoch 19/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0015 - val_loss: 0.0012 - learning_rate: 0.0010\n",
            "Epoch 20/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0012 - val_loss: 0.0011 - learning_rate: 0.0010\n",
            "Epoch 21/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0011 - val_loss: 9.2568e-04 - learning_rate: 0.0010\n",
            "Epoch 22/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 9.8698e-04 - val_loss: 8.7994e-04 - learning_rate: 0.0010\n",
            "Epoch 23/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 8.9680e-04 - val_loss: 0.0012 - learning_rate: 0.0010\n",
            "Epoch 24/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.5877e-04 - val_loss: 6.9058e-04 - learning_rate: 0.0010\n",
            "Epoch 25/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 7.0025e-04 - val_loss: 6.6854e-04 - learning_rate: 0.0010\n",
            "Epoch 26/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.7502e-04 - val_loss: 7.6871e-04 - learning_rate: 0.0010\n",
            "Epoch 27/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.4962e-04 - val_loss: 6.1801e-04 - learning_rate: 0.0010\n",
            "Epoch 28/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.9153e-04\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.9176e-04 - val_loss: 6.2795e-04 - learning_rate: 0.0010\n",
            "Epoch 29/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 4.3215e-04 - val_loss: 5.4664e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 30/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.6028e-04 - val_loss: 6.1898e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 31/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 4.3548e-04 - val_loss: 6.0230e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 32/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 4.3191e-04 - val_loss: 5.0425e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 33/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.0745e-04\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 4.0688e-04 - val_loss: 5.3000e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 34/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.7598e-04 - val_loss: 5.1208e-04 - learning_rate: 2.5000e-04\n",
            "Epoch 35/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.6737e-04 - val_loss: 4.8282e-04 - learning_rate: 2.5000e-04\n",
            "Epoch 36/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.4894e-04 - val_loss: 4.4561e-04 - learning_rate: 2.5000e-04\n",
            "Epoch 37/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.7367e-04 - val_loss: 4.2123e-04 - learning_rate: 2.5000e-04\n",
            "Epoch 38/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.4171e-04 - val_loss: 5.8982e-04 - learning_rate: 2.5000e-04\n",
            "Epoch 39/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 3.2462e-04 - val_loss: 5.2074e-04 - learning_rate: 2.5000e-04\n",
            "Epoch 40/60\n",
            "\u001b[1m20/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.1333e-04\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.1426e-04 - val_loss: 4.3491e-04 - learning_rate: 2.5000e-04\n",
            "Epoch 41/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.2456e-04 - val_loss: 4.5896e-04 - learning_rate: 1.2500e-04\n",
            "Epoch 42/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.1158e-04 - val_loss: 4.3151e-04 - learning_rate: 1.2500e-04\n",
            "Epoch 43/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.1828e-04 - val_loss: 4.2048e-04 - learning_rate: 1.2500e-04\n",
            "Epoch 44/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.5389e-04\n",
            "Epoch 44: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.5171e-04 - val_loss: 4.4996e-04 - learning_rate: 1.2500e-04\n",
            "Epoch 45/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.9523e-04 - val_loss: 4.2545e-04 - learning_rate: 6.2500e-05\n",
            "Epoch 46/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.9464e-04 - val_loss: 4.5348e-04 - learning_rate: 6.2500e-05\n",
            "Epoch 47/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.0499e-04 - val_loss: 4.4474e-04 - learning_rate: 6.2500e-05\n",
            "Epoch 48/60\n",
            "\u001b[1m20/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.1437e-04\n",
            "Epoch 48: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.1393e-04 - val_loss: 4.3286e-04 - learning_rate: 6.2500e-05\n",
            "Epoch 49/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 3.0868e-04 - val_loss: 4.3408e-04 - learning_rate: 3.1250e-05\n",
            "Epoch 50/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.0439e-04 - val_loss: 4.1396e-04 - learning_rate: 3.1250e-05\n",
            "Epoch 51/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 3.1513e-04 - val_loss: 4.2700e-04 - learning_rate: 3.1250e-05\n",
            "Epoch 52/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.1142e-04\n",
            "Epoch 52: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 3.1149e-04 - val_loss: 4.3371e-04 - learning_rate: 3.1250e-05\n",
            "Epoch 53/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 2.8484e-04 - val_loss: 4.3613e-04 - learning_rate: 1.5625e-05\n",
            "Epoch 54/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.9041e-04 - val_loss: 4.2544e-04 - learning_rate: 1.5625e-05\n",
            "Epoch 55/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 3.0339e-04 - val_loss: 4.3434e-04 - learning_rate: 1.5625e-05\n",
            "Epoch 56/60\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.9875e-04\n",
            "Epoch 56: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.9810e-04 - val_loss: 4.2423e-04 - learning_rate: 1.5625e-05\n",
            "Epoch 57/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.8035e-04 - val_loss: 4.2367e-04 - learning_rate: 7.8125e-06\n",
            "Epoch 58/60\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.9940e-04 - val_loss: 4.2610e-04 - learning_rate: 7.8125e-06\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step\n",
            "✅ 第 14 个滑动窗口训练完成\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9️⃣ 误差趋势可视化\n",
        "rmse_avg = np.mean(all_rmse_per_step, axis=0)\n",
        "mae_avg = np.mean(all_mae_per_step, axis=0)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(range(1, 6), rmse_avg, marker='o', label='Average RMSE')\n",
        "plt.plot(range(1, 6), mae_avg, marker='s', label='Average MAE')\n",
        "plt.title('End-to-End Optimized Model Sliding Window Error (T+1 ~ T+5)')\n",
        "plt.xlabel('Forecast Day')\n",
        "plt.ylabel('Error (USD)')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "iT7GFVCON9jX",
        "outputId": "3ae158e1-11d9-4feb-d6de-a874e987dbc0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 打印每一步的平均误差\n",
        "print(\"模型评估结果 (T+1 ~ T+5):\")\n",
        "for step in range(5):\n",
        "    rmse_value = np.mean([r[step] for r in all_rmse_per_step])\n",
        "    mae_value = np.mean([m[step] for m in all_mae_per_step])\n",
        "    print(f\"T+{step+1}: 平均 RMSE = {rmse_value:.2f}, 平均 MAE = {mae_value:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jvVIX80Pt2g",
        "outputId": "bea2df19-1411-4e5a-f984-6b1d0ad364ca"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "模型评估结果 (T+1 ~ T+5):\n",
            "T+1: 平均 RMSE = 0.07, 平均 MAE = 0.07\n",
            "T+2: 平均 RMSE = 0.07, 平均 MAE = 0.07\n",
            "T+3: 平均 RMSE = 0.08, 平均 MAE = 0.07\n",
            "T+4: 平均 RMSE = 0.08, 平均 MAE = 0.07\n",
            "T+5: 平均 RMSE = 0.08, 平均 MAE = 0.07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 反归一化 RMSE 和 MAE（GC=F 列）\n",
        "gc_min = scaler.data_min_[0]  # GC=F 原始最小值\n",
        "gc_max = scaler.data_max_[0]  # GC=F 原始最大值\n",
        "\n",
        "rmse_real = rmse_avg * (gc_max - gc_min)\n",
        "mae_real = mae_avg * (gc_max - gc_min)\n",
        "\n",
        "# 打印真实误差\n",
        "for step in range(5):\n",
        "    print(f\"T+{step+1}: 真实 RMSE = {rmse_real[step]:.2f} USD, 真实 MAE = {mae_real[step]:.2f} USD\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQMzf-nkQFrd",
        "outputId": "b6db8cad-d362-44c1-9230-bfd108082ffa"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T+1: 真实 RMSE = 131.15 USD, 真实 MAE = 120.66 USD\n",
            "T+2: 真实 RMSE = 131.81 USD, 真实 MAE = 121.39 USD\n",
            "T+3: 真实 RMSE = 134.84 USD, 真实 MAE = 124.23 USD\n",
            "T+4: 真实 RMSE = 134.20 USD, 真实 MAE = 123.75 USD\n",
            "T+5: 真实 RMSE = 136.52 USD, 真实 MAE = 125.60 USD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 反归一化函数 (仅针对 GC=F)\n",
        "def inverse_transform_gc_only(scaled_values, scaler_obj, feature_index=0):\n",
        "    dummy = np.zeros((scaled_values.shape[0], scaler_obj.scale_.shape[0]))\n",
        "    if scaled_values.ndim == 2:\n",
        "        dummy[:, feature_index] = scaled_values[:, 0]\n",
        "    else:\n",
        "        dummy[:, feature_index] = scaled_values\n",
        "    inversed = scaler_obj.inverse_transform(dummy)[:, feature_index]\n",
        "    return inversed\n",
        "\n",
        "# 获取测试集\n",
        "latest_window = windows[-1]  # 选取最后一个滑动窗口\n",
        "X_test_base = latest_window['X_test']\n",
        "y_test_base = latest_window['y_test']\n",
        "\n",
        "# 计算基准 RMSE\n",
        "pred_base = model.predict(X_test_base)\n",
        "pred_base_inv = inverse_transform_gc_only(pred_base, scaler)\n",
        "y_test_inv = inverse_transform_gc_only(y_test_base, scaler)\n",
        "base_rmse = np.sqrt(mean_squared_error(y_test_inv, pred_base_inv))\n",
        "\n",
        "# 计算特征重要性\n",
        "factor_names = factors.columns.tolist()\n",
        "importance_results = []\n",
        "\n",
        "for idx, feature in enumerate(factor_names):\n",
        "    X_permuted = X_test_base.copy()\n",
        "    # 仅打乱当前特征列\n",
        "    for sample in X_permuted:\n",
        "        np.random.shuffle(sample[:, idx])\n",
        "\n",
        "    pred_permuted = model.predict(X_permuted)\n",
        "    pred_permuted_inv = inverse_transform_gc_only(pred_permuted, scaler)\n",
        "    permuted_rmse = np.sqrt(mean_squared_error(y_test_inv, pred_permuted_inv))\n",
        "\n",
        "    importance_results.append({\n",
        "        'feature': feature,\n",
        "        'rmse_after_permutation': permuted_rmse,\n",
        "        'increase_in_rmse': permuted_rmse - base_rmse\n",
        "    })\n",
        "\n",
        "# 按 RMSE 变化排序\n",
        "importance_results_sorted = sorted(importance_results, key=lambda x: x['increase_in_rmse'], reverse=True)\n",
        "\n",
        "print(\"📊 特征重要性（按 RMSE 变化排序）:\")\n",
        "for res in importance_results_sorted:\n",
        "    print(f\"{res['feature']}: RMSE 增加 = {res['increase_in_rmse']:.2f}\")\n",
        "\n",
        "# 绘制可视化\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.bar([res['feature'] for res in importance_results_sorted], [res['increase_in_rmse'] for res in importance_results_sorted])\n",
        "plt.title(\"Permutation Feature Importance (Higher = More Important)\")\n",
        "plt.ylabel(\"Increase in RMSE\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        },
        "id": "Q1pyYGtzSNrZ",
        "outputId": "faddac46-422a-467c-94c7-dd228da56cdf"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "📊 特征重要性（按 RMSE 变化排序）:\n",
            "('GC=F', 'GC=F'): RMSE 增加 = 9.81\n",
            "CPI: RMSE 增加 = 0.73\n",
            "('DXY', 'DX-Y.NYB'): RMSE 增加 = 0.00\n",
            "('VIX', '^VIX'): RMSE 增加 = -0.07\n",
            "('SP500', '^GSPC'): RMSE 增加 = -0.49\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}